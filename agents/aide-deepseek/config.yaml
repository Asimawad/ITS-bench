vars:
  step_count: &step_count 25
  time_limit: &time_limit 7200 # 9 h # 24 hrs

defaults: &defaults
  start: aide-deepseek/start.sh
  dockerfile: Dockerfile
  kwargs_type: omegaconf
  env_vars: &env_vars
    TIME_LIMIT_SECS: *time_limit
    STEP_LIMIT: *step_count

kwargs_common: &kwargs_common
  agent.search.max_debug_depth: 20 # debug down a branch for up to 20 steps
  agent.search.debug_prob: 0.7 # always debug when there's something to debug
  agent.time_limit: *time_limit
  exec.timeout: 300 # 2 h# 9 hours limit _per step_, to match max of kaggle.com
  copy_data: False # use symbolic links

aide:
  <<: *defaults
  kwargs:
    <<: *kwargs_common
    agent.code.model: gpt-4-turbo # RedHatAI/DeepSeek-R1-Distill-Qwen-14B-FP8-dynamic #RedHatAI/DeepSeek-R1-Distill-Qwen-32B-FP8-dynamic #o3-mini #ModelCloud/DeepSeek-R1-Distill-Qwen-7B-gptqmodel-4bit-vortex-v2 #deepseek-ai/DeepSeek-R1-Distill-Qwen-7B #deepseek-r1:latest
    agent.feedback.model: o3-mini
    agent.steps: *step_count
    agent.ITS_Strategy: "None"
    # inference_engine: vllm
  env_vars:
    <<: *env_vars
    OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
